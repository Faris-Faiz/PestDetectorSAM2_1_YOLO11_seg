{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "import os\n",
    "\n",
    "rf = Roboflow(api_key=\"<API KEY HERE>\")\n",
    "project = rf.workspace(\"robocup-9jdud\").project(\"black-parts-panorama-image\")\n",
    "version = project.version(4)\n",
    "dataset = version.download(\"sam2\")\n",
    "\n",
    "# rename dataset.location to \"data\"\n",
    "os.rename(dataset.location, \"/scr/user/farisfaiz/batch_connect/sys/jupyter/output/8c6f0e8e-3adc-4485-9aa3-dca2edc863b6/sam2.1_training/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/facebookresearch/sam2.git\n",
    "!wget -O /scr/user/farisfaiz/batch_connect/sys/jupyter/output/8c6f0e8e-3adc-4485-9aa3-dca2edc863b6/sam2.1_training/sam2/sam2/configs/train.yaml 'https://drive.usercontent.google.com/download?id=11cmbxPPsYqFyWq87tmLgBAQ6OZgEhPG3'\n",
    "%cd ./sam2_clonedrepo/\n",
    "!pip install -e .[dev] -q\n",
    "!cd ./checkpoints && ./download_ckpts.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to rename roboflow filenames to something SAM 2.1 compatible.\n",
    "# It may be possible to remove this step by tweaking sam2/sam2/configs/train.yaml.\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Define the folder containing the files to rename\n",
    "FOLDER = \"/scr/user/farisfaiz/batch_connect/sys/jupyter/output/8c6f0e8e-3adc-4485-9aa3-dca2edc863b6/sam2.1_training/data/train\"\n",
    "\n",
    "def rename_files(folder):\n",
    "    try:\n",
    "        # Ensure the folder exists\n",
    "        if not os.path.exists(folder):\n",
    "            raise FileNotFoundError(f\"Specified folder does not exist: {folder}\")\n",
    "        \n",
    "        # Get the list of files\n",
    "        files = os.listdir(folder)\n",
    "        if not files:\n",
    "            print(f\"No files found in the folder: {folder}\")\n",
    "            return\n",
    "        \n",
    "        for filename in files:\n",
    "            old_path = os.path.join(folder, filename)\n",
    "            # Ensure it's a file and not a directory\n",
    "            if not os.path.isfile(old_path):\n",
    "                print(f\"Skipping non-file item: {filename}\")\n",
    "                continue\n",
    "            \n",
    "            # Replace all except the last dot with underscores\n",
    "            new_filename = filename.replace(\".\", \"_\", filename.count(\".\") - 1)\n",
    "            \n",
    "            # Add a numeric suffix if the filename doesn't already have one\n",
    "            if not re.search(r\"_\\d+\\.\\w+$\", new_filename):\n",
    "                base, ext = os.path.splitext(new_filename)\n",
    "                new_filename = f\"{base}_1{ext}\"\n",
    "            \n",
    "            new_path = os.path.join(folder, new_filename)\n",
    "            \n",
    "            # Rename the file and report the change\n",
    "            os.rename(old_path, new_path)\n",
    "            print(f\"Renamed: {filename} -> {new_filename}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Call the function\n",
    "rename_files(FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd sam2\n",
    "%ls\n",
    "!python training/train.py -c 'configs/train.yaml' --use-cluster 0 --num-gpus 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --bind_all --logdir ./sam2_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../..\n",
    "%pip show sam2\n",
    "!pip install supervision -q\n",
    "\n",
    "import torch\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
    "import supervision as sv\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "from skimage.draw import polygon  # Added for mask generation\n",
    "\n",
    "# use bfloat16 for the entire notebook\n",
    "# from Meta notebook\n",
    "torch.autocast(\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "if torch.cuda.get_device_properties(0).major >= 8:\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "parent_directory = \"/scr/user/farisfaiz/batch_connect/sys/jupyter/output/8c6f0e8e-3adc-4485-9aa3-dca2edc863b6/sam2.1_training\"\n",
    "\n",
    "checkpoint = parent_directory + \"/sam2_clonedrepo/sam2_logs/configs/train.yaml/checkpoints/checkpoint.pt\"\n",
    "model_cfg = \"configs/sam2.1/sam2.1_hiera_b+.yaml\"\n",
    "#model_cfg = \"configs/sam2.1/sam2.1_hiera_l.yaml\"\n",
    "sam2 = build_sam2(model_cfg, checkpoint, device=\"cuda\")\n",
    "mask_generator = SAM2AutomaticMaskGenerator(sam2)\n",
    "\n",
    "checkpoint_base = parent_directory + \"/sam2_clonedrepo/checkpoints/sam2.1_hiera_base_plus.pt\"\n",
    "#model_cfg_base = \"configs/sam2.1/sam2.1_hiera_l.yaml\"\n",
    "model_cfg_base = \"configs/sam2.1/sam2.1_hiera_b+.yaml\"\n",
    "sam2_base = build_sam2(model_cfg_base, checkpoint_base, device=\"cuda\")\n",
    "mask_generator_base = SAM2AutomaticMaskGenerator(sam2_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Dice coefficient\n",
    "def dice_coefficient(pred_mask, gt_mask):\n",
    "    intersection = np.logical_and(pred_mask, gt_mask).sum()\n",
    "    union = pred_mask.sum() + gt_mask.sum()\n",
    "    if union == 0:\n",
    "        return 1.0\n",
    "    return 2 * intersection / union\n",
    "\n",
    "# Function to calculate IoU (Intersection over Union)\n",
    "def iou_score(pred_mask, gt_mask):\n",
    "    intersection = np.logical_and(pred_mask, gt_mask).sum()\n",
    "    union = np.logical_or(pred_mask, gt_mask).sum()\n",
    "    if union == 0:\n",
    "        return 1.0\n",
    "    return intersection / union\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(mask_generator, image_path, gt_path):\n",
    "    # Load image and generate predictions\n",
    "    image = np.array(Image.open(image_path).convert(\"RGB\"))\n",
    "    result = mask_generator.generate(image)\n",
    "    \n",
    "    # Load ground truth masks from JSON\n",
    "    with open(gt_path, 'r') as f:\n",
    "        gt_data = json.load(f)\n",
    "    \n",
    "    # Convert ground truth annotations to masks\n",
    "    height, width = image.shape[:2]\n",
    "    gt_masks = []\n",
    "    for annotation in gt_data['annotations']:\n",
    "        mask = np.zeros((height, width), dtype=bool)\n",
    "        # Convert segmentation polygon to mask\n",
    "        for segment in annotation['segmentation']:\n",
    "            poly = np.array(segment).reshape(-1, 2)\n",
    "            rr, cc = polygon(poly[:, 1], poly[:, 0], shape=(height, width))\n",
    "            mask[rr, cc] = True\n",
    "        gt_masks.append(mask)\n",
    "    \n",
    "    # Calculate metrics for each predicted mask against all ground truth masks\n",
    "    dice_scores = []\n",
    "    iou_scores = []\n",
    "    \n",
    "    for pred_mask in result:\n",
    "        pred_binary = pred_mask['segmentation']\n",
    "        # Calculate best score against all ground truth masks\n",
    "        max_dice = max(dice_coefficient(pred_binary, gt) for gt in gt_masks)\n",
    "        max_iou = max(iou_score(pred_binary, gt) for gt in gt_masks)\n",
    "        dice_scores.append(max_dice)\n",
    "        iou_scores.append(max_iou)\n",
    "    \n",
    "    # Calculate mean scores\n",
    "    mDice = np.mean(dice_scores) if dice_scores else 0\n",
    "    mIoU = np.mean(iou_scores) if iou_scores else 0\n",
    "    \n",
    "    return mDice, mIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = os.listdir(parent_directory+\"/data/valid\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "total_dice = 0\n",
    "total_iou = 0\n",
    "count = 0\n",
    "\n",
    "for img_file in [f for f in validation_set if f.endswith('.jpg')]:\n",
    "    img_path = os.path.join(parent_directory + \"/data/valid\", img_file)\n",
    "    gt_path = img_path.replace('.jpg', '.json')\n",
    "    \n",
    "    if os.path.exists(gt_path):\n",
    "        dice, iou = evaluate_model(mask_generator, img_path, gt_path)\n",
    "        total_dice += dice\n",
    "        total_iou += iou\n",
    "        count += 1\n",
    "        print(f\"Image {img_file}: mDice = {dice:.4f}, mIoU = {iou:.4f}\")\n",
    "\n",
    "if count > 0:\n",
    "    print(f\"\\nOverall Metrics:\")\n",
    "    print(f\"Mean Dice Score: {total_dice/count:.4f}\")\n",
    "    print(f\"Mean IoU Score: {total_iou/count:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original visualization code\n",
    "image = random.choice([img for img in validation_set if img.endswith(\".jpg\")])\n",
    "image = os.path.join(parent_directory + \"/data/valid\", image)\n",
    "opened_image = np.array(Image.open(image).convert(\"RGB\"))\n",
    "result = mask_generator.generate(opened_image)\n",
    "\n",
    "detections = sv.Detections.from_sam(sam_result=result)\n",
    "\n",
    "mask_annotator = sv.MaskAnnotator(color_lookup = sv.ColorLookup.INDEX)\n",
    "annotated_image = opened_image.copy()\n",
    "annotated_image = mask_annotator.annotate(annotated_image, detections=detections)\n",
    "\n",
    "base_annotator = sv.MaskAnnotator(color_lookup = sv.ColorLookup.INDEX)\n",
    "\n",
    "base_result = mask_generator_base.generate(opened_image)\n",
    "base_detections = sv.Detections.from_sam(sam_result=base_result)\n",
    "base_annotated_image = opened_image.copy()\n",
    "base_annotated_image = base_annotator.annotate(base_annotated_image, detections=base_detections)\n",
    "\n",
    "sv.plot_images_grid(images=[annotated_image, base_annotated_image], titles=[\"Fine-Tuned SAM-2.1\", \"Base SAM-2.1\"], grid_size=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = random.choice([img for img in validation_set if img.endswith(\".jpg\")])\n",
    "image = os.path.join(parent_directory + \"/data/valid\", image)\n",
    "opened_image = np.array(Image.open(image).convert(\"RGB\"))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "imgplot = plt.imshow(opened_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = mask_generator.generate(opened_image)\n",
    "detections = sv.Detections.from_sam(sam_result=result)\n",
    "mask_annotator = sv.MaskAnnotator(color_lookup = sv.ColorLookup.INDEX)\n",
    "annotated_image = opened_image.copy()\n",
    "annotated_image = mask_annotator.annotate(annotated_image, detections=detections)\n",
    "\n",
    "masked_plot = plt.imshow(annotated_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv.plot_images_grid(images=[annotated_image, opened_image], titles=[\"Segmented Image\", \"Unsegmented Image\"], grid_size=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axes[0].imshow(annotated_image)\n",
    "axes[0].set_title('Segmented Image')\n",
    "axes[0].axis('off')  # Hide axes for clarity\n",
    "\n",
    "axes[1].imshow(opened_image)\n",
    "axes[1].set_title('Unsegmented Image')\n",
    "axes[1].axis('off')  # Hide axes for clarity\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
